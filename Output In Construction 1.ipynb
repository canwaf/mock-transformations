{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output In The Construction Industry\n",
    "\n",
    "-----\n",
    "\n",
    "### Requirements\n",
    "\n",
    "We're looking to transform **tabs 1 and 2 only**.\n",
    "\n",
    "#### Observations & Dimensions\n",
    "\n",
    "The `observations` should be apparent.\n",
    "\n",
    "The required dimensions are:\n",
    "\n",
    "* **Geography** - it's all UK level data (the code for UK is \"K02000001\")\n",
    "* **Time** - either a simple year, or a year followed by a quarter, i.e \"2002 Q2\"\n",
    "* **Adjustment** - either seasonal or non-seasonal\n",
    "* **Business** - concatenation of rows 6-9 around hyphens. i.e 'Other New Work - Excluding Infrastructure - Private Commercial'\n",
    "* **CDID** - ONS specific 4 letter codes. Typically on row 10 \n",
    "\n",
    "-----\n",
    "Notes:\n",
    "\n",
    "* Getting the **Business** dimension cleanly is going to be tricky (read - cant see an obvious way to do it), I'd perhaps leave this one until last.\n",
    "* It's always worth getting the file out of /sources and having a look over.\n",
    "* You can't really take CDID as a dimension (dimension items needs to be repeating, not unqiue), it's a good exercise though as if doing this for real we'd likely be taking it as meta/supporting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/workspace/mock-transformations\n"
     ]
    }
   ],
   "source": [
    "%cd mock-transformations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading ./sources/OIC.xls which has size 759808 bytes\n",
      "Table names: ['Cover Sheet', 'Contents', 'Table 1a', 'Table 1b', 'Table 2a', 'Table 2b', 'Table 3a', 'Table 3b', 'Table 3c', 'Table 3d', 'Table 4', 'Table 4a', 'Table 5a', 'Table 5b', 'Table 6a', 'Table 7', 'Table 8', 'Table 9', 'Table 10', 'Table 11']\n"
     ]
    }
   ],
   "source": [
    "from databaker.framework import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tabs = loadxlstabs(\"./sources/OIC.xls\") # load tabs"
   ]
  },
  {
   "source": [
    "# Thar be dragons\n",
    "The hierarchy associated with the Business sector and the CDID should be treated as a seperate transform, and then joined together at the end. This will make the transform simpler.\n",
    "\n",
    "## Transform steps\n",
    "1. Process headers as a dataset with the CDIDs as observations\n",
    "2. Process observations as a dataset with the CDIDs as a dimension\n",
    "3. Merge headers and observations on the CDIDs to create a new complete dataframe\n",
    "\n",
    "### Headers/Observations\n",
    "|       | Column A | Column B      | Column C  | Column D      |  Column E     |   Column F    |\n",
    "|-------|----------|---------------|-----------|---------------|---------------|---------------|\n",
    "| Row 1 | YYYY MMM | Category A    |           | Category B    |               | Category C    |\n",
    "| Row 2 | YYYY MMM | Subcategory 1 |           | Subcategory 2 | Subcategory 3 | Subcategory 4 |\n",
    "| Row 3 | YYYY MMM | Detail i      | Detail ii | Detail iii    | Detail iv     | Detail v      |\n",
    "| Row 4 | YYYY MMM | Code 1        | Code 2    | Code 3        | Code 4        | Code 5        |\n",
    "| Row 5 | YYYY MMM | OBS v         | OBS w     | OBS x         | OBS y         | OBS z         |\n",
    "\n",
    "* Codes 1 through 5 should be treated as the observations, and the Categories, Subcategories, Details should be treated as a dimension\n",
    "* The acutal Observations (Row 5 and below) should be lined with the CDID (e.g. Codes 1-5) and the dates.\n",
    "* Provide up-to three levels of business classification dimentions\n",
    "\n",
    "## Other notes\n",
    "* Units should be confirmed that these values are indexed to 2016=100."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_headers(tab) -> pd.DataFrame:\n",
    "    # We're futorunate that all the header information is the same\n",
    "    business_level1 = tab.excel_ref(\"C6\").expand(RIGHT)\n",
    "    business_level2 = tab.excel_ref(\"C7\").expand(RIGHT)\n",
    "    business_level3 = tab.excel_ref(\"C8\").expand(RIGHT)\n",
    "\n",
    "    # These are the CDIDs\n",
    "    observations = tab.excel_ref(\"C10\").expand(RIGHT).is_not_blank()\n",
    "\n",
    "    dimensions = [HDim(business_level1, \"business_level1\", CLOSEST, LEFT),\n",
    "                  HDim(business_level2, \"business_level2\", CLOSEST, LEFT),\n",
    "                  HDim(business_level3, \"business_level3\", CLOSEST, LEFT)]\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    headers_and_codes = ConversionSegment(tab, dimensions, observations).topandas()\n",
    "    # Convert empty strings to nans\n",
    "    headers_and_codes = headers_and_codes.replace(r'', np.nan)\n",
    "    # Transpose\n",
    "    headers_only = headers_and_codes.transpose()\n",
    "    # Omit the codes and fill down on nans\n",
    "    headers_only = headers_only.iloc[2:].fillna(method='ffill')\n",
    "    # Transpose again and fill down on nans\n",
    "    headers_only = headers_only.transpose().fillna(method='ffill')\n",
    "\n",
    "    # Compare values between business_level2 and busines_level3, clear dupes on latter\n",
    "    mask = (headers_only.loc[:,'business_level3'] == headers_only.loc[:,'business_level2'])\n",
    "    headers_only.loc[mask, 'business_level3'] = np.nan\n",
    "\n",
    "    # Compare values between business_level1 and busines_level2, clear dupes on latter\n",
    "    mask = (headers_only.loc[:,'business_level2'] == headers_only.loc[:,'business_level1'])\n",
    "    headers_only.loc[mask, 'business_level2'] = np.nan\n",
    "\n",
    "    # Join\n",
    "    headers_and_codes = pd.concat([headers_only, headers_and_codes.iloc[:,1]], axis=1)\n",
    "    return headers_and_codes\n",
    "    # This is likely broken as the levels aren't closest left. Check the output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_contents(tab) -> pd.DataFrame:\n",
    "    # Start of the CDIDs is the same throughout all the tabs\n",
    "    cdids = tab.excel_ref(\"C10\").expand(RIGHT).is_not_blank()\n",
    "\n",
    "    # There are up-to two levels of the time dimension\n",
    "    time_level1 = tab.excel_ref(\"A11\").expand(DOWN).is_not_blank()\n",
    "    time_level2 = tab.excel_ref(\"B11\").expand(DOWN)\n",
    "\n",
    "    # Put the üçÅ syrup away, no waffle here sadly\n",
    "    observations = tab.excel_ref(\"C11\").expand(DOWN).expand(RIGHT).is_not_blank()\n",
    "\n",
    "    dimensions = [HDim(time_level1, \"time_level1\", CLOSEST, ABOVE),\n",
    "                  HDim(time_level2, \"time_level2\", DIRECTLY, LEFT),\n",
    "                  HDim(cdids, \"CDIDs\", DIRECTLY, ABOVE),\n",
    "                  HDimConst(\"units\", tab.excel_ref(\"P5\").value)]\n",
    "    \n",
    "    return ConversionSegment(tab, dimensions, observations).topandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(        OBS time_level1 time_level2 CDIDs     units\n",
       " 0      38.9      1997.0              MV3J  2016=100\n",
       " 1      52.7      1997.0              MV3K  2016=100\n",
       " 2      50.8      1997.0              MVL8  2016=100\n",
       " 3      69.0      1997.0              MV3L  2016=100\n",
       " 4      49.3      1997.0              MV3M  2016=100\n",
       " ...     ...         ...         ...   ...       ...\n",
       " 3173  104.8      2019.0        July  MV3R  2016=100\n",
       " 3174  103.5      2019.0        July  MV3S  2016=100\n",
       " 3175  118.9      2019.0        July  MV3T  2016=100\n",
       " 3176  110.9      2019.0        July  MV3U  2016=100\n",
       " 3177  113.7      2019.0        July  MV3V  2016=100\n",
       " \n",
       " [3178 rows x 5 columns],\n",
       "                business_level1           business_level2     business_level3  \\\n",
       " 0                  New Housing                    Public                 NaN   \n",
       " 1                  New Housing                   Private                 NaN   \n",
       " 2                Total Housing                       NaN                 NaN   \n",
       " 3               Other New Work           Infrastruc-ture                 NaN   \n",
       " 4               Other New Work  Excluding Infrastructure              Public   \n",
       " 5               Other New Work  Excluding Infrastructure  Private Industrial   \n",
       " 6               Other New Work  Excluding Infrastructure  Private Commercial   \n",
       " 7                 All New Work                       NaN                 NaN   \n",
       " 8       Repair and Maintenance                   Housing              Public   \n",
       " 9       Repair and Maintenance                   Housing             Private   \n",
       " 10      Repair and Maintenance                   Housing               Total   \n",
       " 11      Repair and Maintenance           Non Housing R&M                 NaN   \n",
       " 12  All Repair and Maintenance                       NaN                 NaN   \n",
       " 13                    All Work                       NaN                 NaN   \n",
       " \n",
       "    DATAMARKER  \n",
       " 0        MV3J  \n",
       " 1        MV3K  \n",
       " 2        MVL8  \n",
       " 3        MV3L  \n",
       " 4        MV3M  \n",
       " 5        MV3N  \n",
       " 6        MV3O  \n",
       " 7        MV3P  \n",
       " 8        MV3Q  \n",
       " 9        MV3R  \n",
       " 10       MV3S  \n",
       " 11       MV3T  \n",
       " 12       MV3U  \n",
       " 13       MV3V  )"
      ]
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "fetch_contents(tabs[3]), fetch_headers(tabs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tab in tabs:\n",
    "    if tab.name not in ['Table 1a', 'Table 1b', 'Table 2a', 'Table 2b']:\n",
    "        continue\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}